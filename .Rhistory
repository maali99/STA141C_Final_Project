for (i in seq_len(n))
output[j] = output[j] + x[i, j] }
output
}
(x <- matrix(rnorm(9), nc = 3))
rm(x)
rm(X)
rm(colSumsC,colSumsR)
rm(frobeniusR())
rm(frobeniusR)
frobeniusR <- function(X) {
sum(X^2)
}
X <- matrix(runif(1e7), nc = 1e3)
system.time(frobeniusR(X))
colSumsR <- function(x) {
m <- ncol(x)
n <- nrow(x)
output <- double(m)
for (j in seq_len(m)) {
output[j] = 0
for (i in seq_len(n))
output[j] = output[j] + x[i, j] }
output
}
bench::mark(
"origin" = {colSumsR},
"newversion" = {colSumsR})
rm(colSumsC,colSumsR())
rm(colSumsC,colSumsR)
frobeniusR <- function(X) {
sum(X^2)
}
X <- matrix(runif(1e7), nc = 1e3)
system.time(frobeniusR(X))
bench::mark(
"origin" = {frobeniusR()},
"newversion" = {frobeniusC()})
bench::mark(
"origin" = {frobeniusR(X)},
"newversion" = {frobeniusC(X)})
X <- matrix(runif(1e7), nc = 1e3)
system.time(frobeniusR(X))
frobeniusR(X)
type(frobeniusR(X))
typeof(frobeniusR(X))
typeof(frobeniusR(X))
typeof(output)
bench::mark(
"origin" = {frobeniusR(X)},
"newversion" = {frobeniusC(X)})
bench::mark(
"origin" = {frobeniusR(X)},
"newversion" = {as.double(frobeniusC(X))})
frobeniusC(X)
frobeniusC(X)
bench::mark(
"origin" = {frobeniusR(X)},
"newversion" = {as.double(frobeniusC(X))})
frobeniusC(X)
typeof(frobeniusC(X))
typeof(frobeniusR(X))
(frobeniusR(X))
std::transform(Array1.begin(), Array1.end(), Array1.begin(), (double(*)(double)) sqrt);
frobeniusC(X)
sum(frobeniusC(X)^2)
sum(frobeniusC(X))
bench::mark(
"origin" = {frobeniusR(X)},
"newversion" = {sum(frobeniusC(X))})
typeof(sum(frobeniusC(X)))
typeof(frobeniusR(X))
frobeniusC(X) == frobeniusR(X)
X
typeof(X)
is.vector(X)
X[1]
X[2]
bench::mark(
"origin" = {frobeniusR(X)},
"newversion" = {sum(frobeniusC(X))})
bench::mark(
"origin" = {frobeniusR(X)},
"newversion" = {sum(frobeniusC(X))})
bench::mark(
"origin" = {frobeniusR(X)},
"newversion" = {frobeniusC(X)})
frobeniusR(X)
frobeniusC(X)
sum(frobeniusC(X))
frobeniusC(X)
bench::mark(
"origin" = {frobeniusR(X)},
"newversion" = {sum(frobeniusC(X))})
frobeniusC(X) == frobeniusR(X)
frobeniusR()
frobeniusR()
frobeniusR(X)
sum(frobeniusC(X))
4998487 - 3332093
bench::mark(
"origin" = {frobeniusR(X)},
"newversion" = {sum(frobeniusC(X)) - 1666394})
sum(frobeniusC(X)) - 1666394 = frobeniusR(X)
sum(frobeniusC(X)) - 1666394 == frobeniusR(X)
sum(frobeniusC(X)) - 1666394
frobeniusR(X)
3332093 == 3332093
typeof(frobeniusR(X))
typeof(frobeniusC(X))
data <- read.table("adult.data")
fullModel = glm(data$V15 ~ ., family = binomial(),data = data)
nullModel = glm(data$V15 ~ 1, family = binomial(), data = data)
suppressWarnings( {
bestforwardAIC=step(nullModel,scope = list(lower = nullModel),direction = "forward") }
)
summary(bestforwardAIC)
View(bestforwardAIC)
rm(bestforwardAIC)
library(tidyverse)
data <- read.table("adult.data")
# my attempt at bootstrapping and selecting best model
my_list <- list()
my_list <- replicate(n= 100, expr = {data.frame(sample_n(data, size = nrow(data), replace = TRUE))}, simplify = F)
models <- lapply(my_list, function(x) {
glm(x$V15 ~ x$V1, family = binomial())
})
View(models)
models[[1]]
View(models)
# null logistic model
nullModel = glm(data$V15 ~ data$V1, family = binomial(), data = data)
View(nullModel)
View(data)
# my attempt at bootstrapping and selecting best model
my_list <- list()
my_list <- replicate(n= 100, expr = {data.frame(sample_n(data, size = nrow(data), replace = TRUE))}, simplify = F)
models <- lapply(my_list, function(x) {
glm(x$V15 ~ 1, family = binomial())
})
rm(nullModel)
View(models)
library(purrr)
library(parallel)
library(tidyverse)
library(tidyverse)
library(purrr)
library(parallel)
data <- read.table("adult.data")
View(data)
filter(data, V13)
filter(data, data$V13)
select(data,data$V2)
select(data,data$V8)
unfactor(data$V1)
data <- read.csv("adult.data")
data <- read.csv("adult.data", header = FALSE)
data <- names("test")
data <- read.csv("adult.data", header = FALSE)
data$V1
data$V2
View(data)
data <- select(data, data$V1,data$V2,data$V5,data$V9,data$V10,data$V13,data$V15)
data <- select(data, [data$V1,data$V2,data$V5,data$V9,data$V10,data$V13,data$V15])
data <- subset(data, select = -c(data$V3,data$V4,data$V6,data$V7,data$V8,data$V11,data$V12,data$V14))
View(data)
data <- read.csv("adult.data", header = FALSE)
View(data)
data <- drop_na(data)
data <- read.csv("adult.data", header = FALSE)
data <- drop_na(data)
data <- read.csv("adult.data", header = FALSE)
data <- select(data, c(data$V1,data$V2,data$V5,data$V9,data$V10,data$V13,data$V15))
data <- select(data, c(data$V1,data$V2,data$V5,data$V9,data$V10,data$V13,data$))
data <- select(data, c(data$V1,data$V2,data$V5,data$V9,data$V10,data$V13,data$V15))
select(data, c(data$V1,data$V2,data$V5,data$V9,data$V10,data$V13,data$V15))
select(data, -c(data$V1,data$V2,data$V5,data$V9,data$V10,data$V13,data$V15))
test <- select(data, -c(data$V1,data$V2,data$V5,data$V9,data$V10,data$V13,data$V15))
data$V9
rm(test)
my_list <- list()
my_list <- replicate(n= 100, expr = {data.frame(sample_n(data, size = nrow(data), replace = TRUE))}, simplify = F)
View(my_list)
#best logistic model derived from bootstrapping data
model = glm(data$V15 ~ data$V1, data$V2, data$V5, data$V9, data$V10, data$V13, data = data)
#best logistic model derived from bootstrapping data
model = glm(data$V15 ~ data$V1, data$V2, data$V5, data$V9, data$V10, data$V13, data = data)
data$V2
data$V1
data$V5
data$V9
#best logistic model derived from bootstrapping data
model = glm(data$V15 ~ data$V1, data$V2, data$V5, data$V9, data$V10, data$V13, family = binomial(), data = data)
#best logistic model derived from bootstrapping data
model = glm(data$V15 ~ data$V1, data$V2, data$V5, data$V9, data$V10, data$V13, data = data)
data$V13
data$V10
data$V9
data$V5
data$V2
#best logistic model derived from bootstrapping data
model = glm(data$V15 ~ data$V1, data$V2, data$V5, data$V9, data$V10, data$V13, family = bimonial(), data = data)
#best logistic model derived from bootstrapping data
model = glm(data$V15 ~ data$V1, data$V2, data$V5, data$V9, data$V10, data$V13, family = binomial(), data = data)
model <- glm(data$V15 ~ data$V1)
data$V15
colnames(data) <- c("Age", "Workclass", "fnlwgt", "Education", "Education_num", "Marital", "Occupation", "Relationship", "Race", "Sex", "Capital_gain", "Capital_loss", "Hours_week", "Country", "Income")
# Our chosen logistic regression model
model = glm(Income ~ Age, family = binomial(), data = data)
View(model)
# The full and null models for comparison
full_model = glm(Income ~ ., family = binomial(), data = data)
null_model = glm(Income ~ 1, family = binomial(), data = data)
rm(my_list)
library(reticulate)
# if you use virtualenv instead, you would comment the follow code and change to the virtualenv alternative
# create an conda env for R
if (!("r-reticulate" %in% conda_list()$name)) {
conda_create("r-reticulate")
}
library(reticulate)
# if you use virtualenv instead, you would comment the follow code and change to the virtualenv alternative
# create an conda env for R
if (!("r-reticulate" %in% conda_list()$name)) {
conda_create("r-reticulate")
}
use_condaenv("r-reticulate", required = TRUE)
test <- find_factors(120)
print(answer)
py$find_factors(120)
py$find_factors(x = 120)
print(py$answer)
py$find_factors
py$find_factors
py$find_factors(12)
as.integer(120)
py$find_factors(as.integer(120))
py$solve_quad(1,1,1)
# Solving x^2 + x + 1 = 0
py$solve_quad(1,1,1)
py_install("sklearn", pip = TRUE)
py_install("sklearn", pip = TRUE)
py$pylm(c(disp,hp,wt), mpg)
```{r cars}
py$pylm(c(disp,hp,wt), mpg)
mtcars
mtcars$mpg
```{r mtcars}
py$pylm(c(disp,hp,wt), mpg)
py$pylm(c(mtcars$disp,mtcars$hp,mtcars$wt), mtcars$mpg)
py$pylm(mtcars$hp, mtcars$mpg)
t(mtcars$hp)
mtcars$hp
t(t(mtcars$hp))
py$pylm(t(t(mtcars$hp)), mtcars$mpg)
py$pylm(t(t(mtcars$hp)), mtcars$mpg)
library(reticulate)
# if you use virtualenv instead, you would comment the follow code and change to the virtualenv alternative
# create an conda env for R
if (!("r-reticulate" %in% conda_list()$name)) {
conda_create("r-reticulate")
}
use_condaenv("r-reticulate", required = TRUE)
py$find_factors(as.integer(120))
# Solving x^2 + x + 1 = 0
py$solve_quad(1,1,1)
py$pylm(t(t(mtcars$hp)), mtcars$mpg)
fit = py$pylm(t(t(mtcars$hp)), mtcars$mpg)
summary(fit)
fit$coef_
disp <- t(t(mtcars$disp))
hp <- t(t(mtcars$hp))
wt <- t(t(mtcars$wt))
fit = py$pylm(c(disp,hp,wt), mtcars$mpg)
rm(disp)
rm(hp,wt)
var1 <- t(t(mtcars$disp))
var2 <- t(t(mtcars$hp))
var3 <- t(t(mtcars$wt))
fit = py$pylm(c(disp,hp,wt), mtcars$mpg)
fit = py$pylm(c(var1,var2,var3), mtcars$mpg)
fit = py$pylm(matrix(var1,var2,var3), mtcars$mpg)
fit = py$pylm(matrix(c(var1,var2,var3)), mtcars$mpg)
fit = py$pylm(var1, mtcars$mpg)
fit$coef_
fit = py$pylm(var2, mtcars$mpg)
fit$coef_
c(var1,var2,var3)
var1 <- mtcars$disp
var2 <- mtcars$hp
var3 <- mtcars$wt
c(var1,var2,var3)
t(c(var1,var2,var3))
var1 <- mtcars$disp
var3 <- mtcars$wt
fit = py$pylm(t(c(var1,var2,var3)), mtcars$mpg)
library(tidyverse)
predictors <- select(mtcars,disp,hp,wt)
View(predictors)
fit = py$pylm(predictors, mtcars$mpg)
fit = py$pylm(matrix(predictors), mtcars$mpg)
matrix(predictors)
matrix(var1,var2,var3)
matrix(var1,var2,var3)
fit = py$pylm(matrix(var1,var2,var3), mtcars$mpg)
fit = py$pylm(matrix(var1,var2,var3), mtcars$mpg)
fit = py$pylm(matrix(var1,var2,var3), mtcars$mpg)
fit = py$pylm(matrix(var1,var2,var3), mtcars$mpg)
fit = py$pylm(matrix(var1,var2,var3), mtcars$mpg)
fit = py$pylm(matrix(var1,var2,var3), mtcars$mpg)
fit$coef_
fit = py$pylm(matrix(var1,var2,var3), mtcars$mpg)
fit = py$pylm(var1, mtcars$mpg)
fit = py$pylm(t(var1), mtcars$mpg)
fit = py$pylm(t(t(var1)), mtcars$mpg)
fit$coef_
fit = py$pylm(t(t(var1,var2,var3)), mtcars$mpg)
fit = py$pylm(t(t(c(var1,var2,var3))), mtcars$mpg)
fit = py$pylm(t(c(var1,var2,var3)), mtcars$mpg)
fit = py$pylm(t(c(var1,var2,var3)), mtcars$mpg)
cbind(var1,var2,var3)
fit = py$pylm(cbind(var1,var2,var3), mtcars$mpg)
fit$coef_
rm(predictors)
var4 <- as.factor(mtcars$cyl)
fit2 <- py$pylm(cbind(var1,var2,var3,var4), mtcars$mpg)
fit2$coef_
library(tidyverse)
library(reticulate)
# if you use virtualenv instead, you would comment the follow code and change to the virtualenv alternative
# create an conda env for R
if (!("r-reticulate" %in% conda_list()$name)) {
conda_create("r-reticulate")
}
use_condaenv("r-reticulate", required = TRUE)
py$find_factors(as.integer(120))
```{r}
# Solving x^2 + x + 1 = 0
py$solve_quad(1,1,1)
var1 <- mtcars$disp
var2 <- mtcars$hp
var3 <- mtcars$wt
fit = py$pylm(cbind(var1,var2,var3), mtcars$mpg)
# coefficients of all the predictor variables
fit$coef_
# make as factor since cyl is categorical
var4 <- as.factor(mtcars$cyl)
fit2 <- py$pylm(cbind(var1,var2,var3,var4), mtcars$mpg)
# coefficients of all the predictor variables
fit2$coef_
library(tidyverse)
library(purrr)
library(parallel)
setwd("~/GitHub/STA141C_Final_Project")
data <- read.csv("adult.data", header = FALSE)
colnames(data) <- c("Age", "Workclass", "fnlwgt", "Education", "Education_num", "Marital", "Occupation", "Relationship", "Race", "Sex", "Capital_gain", "Capital_loss", "Hours_week", "Country", "Income")
# The full and null models for comparison
full_model = glm(Income ~ ., family = binomial(), data = data)
null_model = glm(Income ~ 1, family = binomial(), data = data)
# Our chosen logistic regression model
model = glm(Income ~ Age, family = binomial(), data = data)
model$coefficients
summary(model)
model[2]
model$coefficients[2]
model$coefficients[1]
model$coefficients[0]
model$coefficients[3]
model$coefficients[4]
model$coefficients[2]
b1 = model$coefficients[2]
b1
exp(b1)
exp(.039)
b1 = model$coefficients[2]
exp(b1)
library(tidyverse)
library(purrr)
library(parallel)
data <- read.csv("adult.data", header = FALSE)
colnames(data) <- c("Age", "Workclass", "fnlwgt", "Education", "Education_num", "Marital", "Occupation", "Relationship", "Race", "Sex", "Capital_gain", "Capital_loss", "Hours_week", "Country", "Income")
# The full and null models for comparison
full_model = glm(Income ~ ., family = binomial(), data = data)
null_model = glm(Income ~ 1, family = binomial(), data = data)
# Our chosen logistic regression model
model <- glm(Income ~ Age + Race + Sex + Education_num + Hours_week, family = binomial, data = data)
summary(model)
View(full_model)
b1 <- model$coefficients[2]
b2 <- model$coefficients[3]
b3 <- model$coefficients[4]
b4 <- model$coefficients[5]
b5 <- model$coefficients[6]
b6 <- model$coefficients[7]
b7 <- model$coefficients[8]
b8 <- model$coefficients[9]
View(model)
# odds of income >=50k given age
exp(b1)
# odds of income >=50k given race is asian-pacific islander
exp(b2)
# odds of income >=50k given race is black
exp(b3)
# odds of income >=50k given race is other
exp(b4)
# odds of income >=50k given race is white
exp(b5)
# odds of income >=50k given sex is male
exp(b6)
# odds of income >=50k given education number
exp(b7)
# odds of income >=50k given hours worked per week
exp(b8)
b5
exp(b5)
summary(model)$coefficients[1,1]
summary(model)$coefficients[1]
summary(model)$coefficients[1,2]
summary(model)$coefficients[1,3]
summary(model)$coefficients[2,1]
model$coefficients[1,2]
model$coefficients[1,1]
model$coefficients[1]
model$coefficients[2]
model$coefficients[2]/2
model
summary(model)
b0 <- model$coefficients[1]
se_b1 <- summary(model)$coefficients[1,2]
se_b1 <- summary(model)$coefficients[2,2]
# beta coefficients and standard error assignments
b0 <- model$coefficients[1]
b1 <- model$coefficients[2]
se_b1 <- summary(model)$coefficients[2,2]
b2 <- model$coefficients[3]
se_b2 <- summary(model)$coefficients[3,2]
b3 <- model$coefficients[4]
se_b3 <- summary(model)$coefficients[4,2]
b4 <- model$coefficients[5]
se_b4 <- summary(model)$coefficients[5,2]
b5 <- model$coefficients[6]
se_b5 <- summary(model)$coefficients[6,2]
b6 <- model$coefficients[7]
se_b6 <- summary(model)$coefficients[7,2]
b7 <- model$coefficients[8]
se_b7 <- summary(model)$coefficients[8,2]
b8 <- model$coefficients[9]
se_b8 <- summary(model)$coefficients[9,2]
# odds of income >=50k given age
exp(b1)
# odds of income >=50k given race is asian-pacific islander
exp(b2)
# odds of income >=50k given race is black
exp(b3)
# odds of income >=50k given race is other
exp(b4)
# odds of income >=50k given race is white
exp(b5)
# odds of income >=50k given sex is male
exp(b6)
# odds of income >=50k given education number
exp(b7)
# odds of income >=50k given hours worked per week
exp(b8)
# odds of income >=50k with all refernce variables active and others held constant
exp(b0)
# beta coefficients and standard error assignments
b0 <- model$coefficients[1]
b1 <- model$coefficients[2]
SE_b1 <- summary(model)$coefficients[2,2]
b2 <- model$coefficients[3]
SE_b2 <- summary(model)$coefficients[3,2]
b3 <- model$coefficients[4]
SE_b3 <- summary(model)$coefficients[4,2]
b4 <- model$coefficients[5]
SE_b4 <- summary(model)$coefficients[5,2]
b5 <- model$coefficients[6]
se_b5 <- summary(model)$coefficients[6,2]
b6 <- model$coefficients[7]
SE_b6 <- summary(model)$coefficients[7,2]
b7 <- model$coefficients[8]
SE_b7 <- summary(model)$coefficients[8,2]
b8 <- model$coefficients[9]
SE_b8 <- summary(model)$coefficients[9,2]
test_stat1 <- (b1-0)/SE_b1
test_stat2 <- (b2-0)/SE_b2
test_stat3 <- (b3-0)/SE_b3
test_stat4 <- (b4-0)/SE_b4
test_stat5 <- (b5-0)/SE_b5
test_stat6 <- (b6-0)/SE_b6
test_stat7 <- (b7-0)/SE_b7
test_stat8 <- (b8-0)/SE_b8
SE_b5 <- summary(model)$coefficients[6,2]
test_stat5 <- (b5-0)/SE_b5
test_stat1
test_stat2
test_stat3
test_stat4
2*(1-pnorm(abs(test_stat1)))
2*(1-pnorm(abs(test_stat2)))
2*(1-pnorm(abs(test_stat3)))
2*(1-pnorm(abs(test_stat4)))
2*(1-pnorm(abs(test_stat5)))
test_stat1
2*(1-pnorm(abs(test_stat1)))
2*(1-pnorm(abs(test_stat2)))
2*(1-pnorm(abs(test_stat3)))
2*(1-pnorm(abs(test_stat4)))
2*(1-pnorm(abs(test_stat5)))
2*(1-pnorm(abs(test_stat6)))
2*(1-pnorm(abs(test_stat7)))
2*(1-pnorm(abs(test_stat8)))
