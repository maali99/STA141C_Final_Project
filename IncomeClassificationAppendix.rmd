---
title: "STA 141C Final Project Appendix"
author: "Eva Chen, Muhammad Ali, Yaosang Zhan, Sukhween Bhullar"
date: "3/19/2020"
output: html_document
---
```{r include=FALSE}
knitr::opts_chunk$set(echo=FALSE)
```
  
Before we begin our model analysis, we did some general exploratory data analysis to explore variables of interest. 
```{r, warning=FALSE, message=FALSE}
#read the data and rename the columns
library(readr)
library(ggplot2)
library(tidyverse)
library(readr)
library(formattable)
url1 <- "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
data1 <- read.csv(url1, header = FALSE)
colnames(data1) <- c("age",
                     "workclass",
                     "fnlwgt",
                     "education",
                     "education_num",
                     "marital_status",
                     "occupation",
                     "relationship",
                     "race",
                     "sex",
                     "capital_gain",
                     "capital_loss",
                     "hours_per_week",
                     "native_country",
                     "income")
#take out the rows with the missing data
data1[data1 == " ?"] = NA
data1 = na.omit(data1)
```

Histograms of all the quantitative variables: age, capital_gain, capital_loss, education_num, hours_per_week, and fnlwgt, were used to visualize the general distributions.
```{r, warning=FALSE, message=FALSE}
#histograms of the continuous quanitative variables 
par(mfrow=c(3,2))
hist(data1$age, xlab="Age", main="Histogram of Age")
hist(data1$capital_gain, xlab="Capital Gain", main="Histogram of Capital Gain")
hist(data1$capital_loss, xlab="Capital Loss", main="Histogram of Capital Loss")
hist(data1$education_num, xlab="Education Number", main="Histogram of Education Number")
hist(data1$hours_per_week, xlab="Hours Per Week", main="Histogram of Hours Per Week")
hist(data1$fnlwgt, xlab="fnlwgt", main="Histogram of `fnlwgt")
par(mfrow=c(1,1))
```

The following graphs show a distribution of our response variable, income. The first chart compares income distribution between males and females. The second graph compares how income distribution amongst different ages. The second chart shows the distribution of income split across different education_num values (each number equates to an education level, ex. 13 is Bachelor's degree) and races. The third chart shows the distribution of income split across different education_num values (each number equates to an education level, ex. 13 is Bachelor's degree) and races. 
```{r, warning=FALSE, message=FALSE}
library(gridExtra)
attach(data1)  
par(mfrow=c(1,3))
# Plot ratios of income in male group and female group
fig = ggplot(data = data1, mapping = aes(x = sex, fill = income))
fig1 = fig + geom_bar(position = "fill")
# plot  the number of income > 50K and income <=50K grouped by race and education
fig = ggplot(data = data1, mapping = aes(x = education_num, fill = income))
fig2 = fig + geom_bar() + facet_grid(race, scales = "free_y")
# plot the distribution of age groupped by income
fig = ggplot(data = data1, mapping = aes(x = age, fill = income, color = income))
fig3 = fig + geom_density(alpha = 0.3)
hours_income = table(data1[,c('hours_per_week','income')])
hours_income <- as.data.frame(prop.table(hours_income, 1))
hours_income_over50 = hours_income[(nrow(hours_income)/2+1):nrow(hours_income),]
fig = ggplot(data = hours_income_over50, 
             mapping = aes(
             x = hours_per_week, 
             y = Freq,
             group = income))
grid.arrange(fig1,fig3)
fig2
detach(data1)
```
The very first step was to split the data into training and test data. To do this we simply used the 80/20 rule, in which 80 percent of our original data would be used to train, while the other 20 percent would be used to test. 
```{r, warning=FALSE, message=FALSE}
#split the rows into testing data and training data 
data1_test= data1[24131:nrow(data1),] #testing data
data1= data1[1:24130,] #training data
```

We used logistic regression without bootstrapping and included all the variables, the end result was a very long list of coefficients. 
```{r, warning=FALSE, message=FALSE}
fullmodel <- glm(income ~., family = binomial, data = data1)
paste("The number of rows in the full logistic model:", nrow(summary(fullmodel)$coef))
coeffs_full <- fullmodel$coefficients
predicted_full<-predict(fullmodel, data1_test, type="response")
#here we implemented the library caret and the predict functionto predict the classes
#we then extracted the accuracy rate from the confusion matrix 
library(caret)
predict_df_full<-as.data.frame(predicted_full)
for(i in seq_len(nrow(data1_test))){
  if(predict_df_full$predicted[i]>.5){
    predict_df_full$class[i] = " >50K"
  }else{
    predict_df_full$class[i] = " <=50K"
  }
}
cmGLM_full<-confusionMatrix(as.factor(predict_df_full$class), data1_test$income)
glm_rate_full<-cmGLM_full$overall[['Accuracy']]*100 
```

By removing all the categorical variables minus race and keeping all the quanitative variables minus capital_gain, capital_loss and fnlgwt we get a manageable model. 
```{r, warning=FALSE, message=FALSE}
#the full model gives us approximately 90 estimates, so we shifted to a simpler model, taking out variables
#with a lot of levels
model1 <- glm(income ~ age + race + sex + education_num + hours_per_week, family = binomial, data = data1)
coeffs_simple <- model1$coefficients
coeffs_simple<-as.data.frame(coeffs_simple)
predicted_m1<-predict(model1, data1_test, type="response")
#here we implemented the library caret and the predict functionto predict the classes
#we then extracted the accuracy rate from the confusion matrix 
library(caret)
predict_df_m1<-as.data.frame(predicted_m1)
for(i in seq_len(nrow(data1_test))){
  if(predict_df_m1$predicted[i]>.5){
    predict_df_m1$class[i] = " >50K"
  }else{
    predict_df_m1$class[i] = " <=50K"
  }
}
cmGLM_m1<-confusionMatrix(as.factor(predict_df_m1$class), data1_test$income)
#the glm accuracy rate is calculated here
glm_rate_m1<-cmGLM_m1$overall[['Accuracy']]*100 
formattable(coeffs_simple)
```


```{r, warning=FALSE, message=FALSE, echo=FALSE}
# For every iteration
# randomize data
# find the slopes
suppressMessages(library(tidyverse))
library(furrr)
plan(multiprocess, workers = 4)
B = 10000
n = nrow(data1)
m <- 10
groups <- sample(seq_len(m), n, replace = TRUE)
subsamples<-map(seq_len(m), ~write_csv(data1[groups==.,], str_c("part",.,".csv")))
single_boot <- function(i, ind_part){
  subsample = read_csv(str_c("part",ind_part, ".csv"))
  freqs = rmultinom(1, n, rep(1, nrow(subsample)))
  model1 <- glm(as.factor(income) ~ age + race + sex + education_num + hours_per_week, weight = freqs, family = binomial, data = subsample)
  return(as.data.frame(t(as.matrix(model1$coefficients))))
}
```

The confidence intervals give us a lower and upper bound for beta estimates:
```{r, warning=FALSE, message=FALSE}
#Confidence interval at alpha =.05
ci_list = future_map(seq_len(m), ~{
  map_dfr(seq_len(B), single_boot, ind_part =.) %>%
    map_dfr(~quantile(., c(0.025,0.975))) } )
ci1 <- reduce(ci_list, `+`) / length(ci_list)
ci_coeffs<-as.data.frame(t(ci1))
ci_coeffs <- ci_coeffs %>% 
  rename("Coefficients_LowerBound"=V1, "Coefficients_UpperBound"=V2)
formattable(ci_coeffs)
```

The medians give the following beta estimates:
```{r, warning=FALSE, message=FALSE}
#median using the median function
med_list = future_map(seq_len(m), ~{
  map_dfr(seq_len(B), single_boot, ind_part =.) %>%
    map_dfr(~median(.)) } )
med1 <- reduce(med_list, `+`) / length(med_list)
med_coeffs<- as.data.frame(t(med1))
med_coeffs<-med_coeffs %>% 
  rename("Coefficients_Median"=V1)
formattable(med_coeffs)
```
   
The means give the following beta estimates:
```{r, warning=FALSE, message=FALSE}
#mean using the mean function
mean_list = future_map(seq_len(m), ~{
  map_dfr(seq_len(B), single_boot, ind_part =.) %>%
    map_dfr(~mean(.)) } )
mean1 <- reduce(mean_list, `+`) / length(mean_list)
mean_coeffs<-as.data.frame(t(mean1))
mean_coeffs<-mean_coeffs %>% 
  rename("Coefficients_Mean"=V1)
formattable(mean_coeffs)
```

The following is the initial tree classification model used on age, workclass, education, marital_status, occupation, relationship, race, capital_gain, capital_loss, hours_per_week and sex. The next step was to create multiple trees, to create a random forest. 
```{r, warning=FALSE, message=FALSE}
#implement the tree function to 
library(tree)
#note we cannot use all the variables because the tree function has a limit to how many levels we can have
#if we add all the variables then we would exceed that limit, so we used most of the variables, but took out a
#a few of them
tree_income <- tree(income ~ 
                      age+
                      workclass+
                      education+
                      marital_status+
                      occupation+
                      relationship+
                      race+
                      capital_gain +
                      capital_loss+
                      hours_per_week+
                      sex, data1)
plot(tree_income, type = "uniform")
text(tree_income, pretty = 1, all = TRUE, cex = 0.7)
#Random Forest
#use the library furrr
suppressMessages(library(tidyverse))
library(furrr)
plan(multiprocess, workers = 4)
#set B to 1000
B <- 10000
#we will be sampling 8 columns for our resampling 
m <- 8
#set n to the number of rows in the training set aka data1
n <- nrow(data1)
#note we are only using the column names below to resample as some of the variables have been dropped
col_names <- c("age","workclass","education","marital_status","occupation","relationship","race","sex", "capital_gain","capital_loss","hours_per_week") 
#we want to predict a class for each row of data in the test data aka dat1_test
#to do this we will have to implement transpose and subsetting later on
#GOAL: we basically want to output a transposed data frame of B rows for each row number in the test data
#WHY: having the row numbers of the test numbers as column names will allow us to easily get average probabilities for >50K and <=50K, then from there we can pass our newly estimated probabilities from bootstrapping to get an accuracy rate for bootstrap_rf
predict_vals<-NULL
random_forest<-future_map_dfr(seq_len(B), function(i) {
  col_names <- c("income", sample(col_names, m)) #selects the col
  income_boot <- data1[sample(n, n, replace = TRUE), col_names]
  tree_income_boot <- tree(income ~ ., income_boot)
  predict_tree<-predict(tree_income_boot, data1_test)
  as.data.frame(t(predict_tree))
})
#the formatting of the transpose makes all even indices as probabilities for being in class >50k and all odd indices as probabilities for being in class <=50K
even_indexes<-seq(2,nrow(random_forest),2) #indices associated with the >50k 
odd_indexes<-seq(1,nrow(random_forest),2) #indices associated with the<=50k
#we want to extract all the odd and even rows into two separate data frames
more_than50K_estimate<-as.data.frame(map_dbl(random_forest[even_indexes,], mean))
less_than50K_estimate<-as.data.frame(map_dbl(random_forest[odd_indexes,], mean))
#we then want to bind the two to create a final data frame that predicts classes for the test data and was acquired from bootstrapping
mean_rf<-cbind(less_than50K_estimate, more_than50K_estimate)
```

An attempt at creating BLB with Random Forests. 
```{r, eval=FALSE, warning=FALSE, message=FALSE}
#use the library furrr
# CODE
# suppressMessages(library(tidyverse))
# library(furrr)
# plan(multiprocess, workers = 4)
# CODE
#set B to 1000
# B <- 2
# CODE
# p<- 10 # the number of subsamples
#we will be sampling 8 columns for our resampling 
# CODE
# m <- 8
#set n to the number of rows in the training set aka data1
# CODE
# n <- nrow(data1)
#note we are only using the column names below to resample as some of the variables have been dropped
# CODE
# col_sample <- c("age","workclass","education","marital_status","occupation","relationship","race","sex", "capital_gain","capital_loss","hours_per_week") 
#we want to predict a class for each row of data in the test data aka dat1_test
#to do this we will have to implement transpose and subsetting later on
#GOAL: we basically want to output a transposed data frame of B rows for each row number in the test data
#WHY: having the row numbers of the test numbers as column names will allow us to easily get average probabilities for >50K and <=50K, then from there we can pass our newly estimated probabilities from bootstrapping to get an accuracy rate for bootstrap_rf
# CODE
# bootstrap_rf<-function(i, ind_part){
#    #selects the col
#   print("hey")
#   col_names <- c("income", sample(col_sample, m)) #selects the col
#   subsample = read_csv(str_c("part",4, ".csv"))
#   income_boot <- subsample[sample(seq.int(subsample), n, replace = TRUE), col_names]
#   #convert variables to factors
#   income_boot <- mutate_if(income_boot, is.character, as.factor)
# 
#   tree_income_boot <- tree(income ~ ., income_boot)
#   predict_tree<-predict(tree_income_boot, data1_test)
#   as.data.frame(t(predict_tree))
# }
# CODE
# future_map(seq_len(p), ~{
#   map_dfr(seq_len(B), bootstrap_rf, ind_part=.)} )
#the formatting of the transpose makes all even indices as probabilities for being in class >50k and all odd indices as probabilities for being in class <=50K
# CODE
# even_indexes<-seq(2,nrow(as.data.frame(t(predict_tree))),2) #indices associated with the >50k
# odd_indexes<-seq(1,nrow(as.data.frame(t(predict_tree))),2) #indices associated with the<=50k
#we want to extract all the odd and even rows into two separate data frames
# CODE
# more_than50K_estimate<-as.data.frame(map_dbl(as.data.frame(t(predict_tree))[even_indexes,], mean))
# less_than50K_estimate<-as.data.frame(map_dbl(as.data.frame(t(predict_tree))[odd_indexes,], mean))
#extra step needed here to construct an aesthetic data frame of the data 
#we then want to bind the two to create a final data frame that predicts classes for the test data and was acquired from bootstrapping
# CODE
# mean_bootstrap_rf<-cbind(less_than50K_estimate, more_than50K_estimate)
#finally pass this newly created data frame into the accuracy calculator that compares predictions to actual
# CODE
# accuracy_val2<-calc_accuracy_rf(data1_test,prediction_rf)
#then we will get an accuracy rate 
# CODE
# (accuracy_val2[1]+accuracy_val2[3])/(nrow(data1_test))*100
```

We then use these numbers to calculate the accuracy rate, which is the correct/total. 
```{r, warning=FALSE, message=FALSE}
#accuray calculator for BLB with logistic regression
#initialize counters
incorrect_50plus=0 #counter for number of incorrect classifications of incomes greater than 50k
correct_50plus=0 #counter for number of correct classifications of incomes greater than 50k
incorrect_50less=0 #counter for number of incorrect classifications of incomes less than 50k
correct_50less=0 #counter for number of correct classifications of incomes less than 50k
predict_blb_glm <-function(method, test_data){
  
  #the accuracy vector will contain a vector of all the counters
  acccuracy_vector <- c("Incorrect(>50k)", "Correct(>50k)","Incorrect(<=50k)", "Correct(<=50k)")
  
  #from the test data select the variables of interest
  test_data <- test_data %>% 
    select(age, race, sex, education_num, hours_per_week,income)
  
  #this for loop will predict the income brackets
  for(i in seq_len(nrow(test_data))){
    
    test_val=test_data[i,]
    
    #we must use multiple if else statements to check for the race variable
    #because it's a categorical variable
    #use the odds= Intercept_est+
        #age_beta1*age +
        #`raceAsian-Pac-Islander`_beta *(0 or 1) +
        #raceBlack_beta *(0 or 1) +
        #raceOther_beta *(0 or 1) +
        #raceWhite_beta *( 0 or 1) +
        #education_num_beta *(education_num) +
        #hours_per_week_beta *(hours_per_week)
    
    if(as.character(droplevels(test_val$race))== " White"){
     odds= method$`(Intercept)`+
        method$age*test_val$age +
        method$`raceAsian-Pac-Islander`*0 +
        method$raceBlack*0 +
        method$raceOther*0 +
        method$raceWhite*1 +
        method$education_num*test_val$education_num +
        method$hours_per_week*test_val$hours_per_week
      
    }else if(as.character(droplevels(test_val$race))==" Asian-Pac-Islander"){
      odds= method$`(Intercept)`+
        method$age*test_val$age +
        method$`raceAsian-Pac-Islander`*1 +
        method$raceBlack*0 +
        method$raceOther*0 +
        method$raceWhite*0 +
        method$education_num*test_val$education_num +
        method$hours_per_week*test_val$hours_per_week
      
    }else if(as.character(droplevels(test_val$race))==" Black"){
      
      odds= method$`(Intercept)`+
        method$age*test_val$age +
        method$`raceAsian-Pac-Islander`*0 +
        method$raceBlack*1 +
        method$raceOther*0 +
        method$raceWhite*0 +
        method$education_num*test_val$education_num +
        method$hours_per_week*test_val$hours_per_week
      
    }else if(as.character(droplevels(test_val$race))==" Other"){
      
      odds= method$`(Intercept)`+
        method$age*test_val$age +
        method$`raceAsian-Pac-Islander`*0 +
        method$raceBlack*0 +
        method$raceOther*1 +
        method$raceWhite*0 +
        method$education_num*test_val$education_num +
        method$hours_per_week*test_val$hours_per_week
      
    }else if(as.character(droplevels(test_val$race))==" Amer-Indian-Eskimo"){
      
      odds= method$`(Intercept)`+
        method$age*test_val$age +
        method$`raceAsian-Pac-Islander`*0 +
        method$raceBlack*0 +
        method$raceOther*0 +
        method$raceWhite*0 +
        method$education_num*test_val$education_num +
        method$hours_per_week*test_val$hours_per_week
      
    }
    
    #use the equation exp(odds)/(1+exp(odds)) to get a probability value
    probability = exp(odds)/(1+exp(odds))
    
    # if the probability is greater than .5 then the predicted income is less than 50k 
    if(probability<.5){
      
      pred_income = " <=50K"
      #if the predicted income for the test data is equal to the actual income, increment the correct counter
      if(pred_income == as.character(droplevels(test_val$income))){ 
        
        correct_50less = correct_50less +1
      }else{
      #otherwise increment incorrect counter
        incorrect_50less = incorrect_50less +1
      }
    
    #otherwise the predicted income is greater than 50k  
    }else{
      
      pred_income = " >50K"
      #if the predicted income for the test data is equal to the actual income, increment the correct counter
      if(pred_income == as.character(droplevels(test_val$income))){
        correct_50plus = correct_50plus +1
      }else{
        #otherwise increment incorrect counter
        incorrect_50plus = incorrect_50plus +1
      }
      
    }
    
    
    accuracy_vector<- c( correct_50plus, incorrect_50plus, correct_50less, incorrect_50less)
    
  }
  
  return(accuracy_vector)
}
```

```{r, warning=FALSE, message=FALSE}
incorrect_50plus2=0 #counter for number of incorrect classifications of incomes greater than 50k
correct_50plus2=0 #counter for number of correct classifications of incomes greater than 50k
incorrect_50less2=0 #counter for number of incorrect classifications of incomes less than 50k
correct_50less2=0 
calc_accuracy_rf<-function(test_data, predicted){
  for(i in seq_len(nrow(predicted))){ #if the probability is higher for >50K then it means that predicted income is >50K
    if(predicted[i,1]<predicted[i,2]){
      
      pred_income = " >50K"
    #if the predicted income is equal to the actual income at that level then increment correct
      if(pred_income == as.character(droplevels(test_data[i,]$income))){
        correct_50plus2= correct_50plus2 +1
      }
      else{
    #otherwise increment incorrect
        incorrect_50plus2 = incorrect_50plus2 + 1
      }
    }else{ #if the probability is less for >50k then it means the predicted is <=50K
      
      pred_income = " <=50K"
    #if the predicted is equal to the actual value of test data at that row 
      if(pred_income == as.character(droplevels(test_data[i,]$income))){
    #then increment the correct counter
        correct_50less2= correct_50less2+1
      }else{
    #otherwise increment incorrect
        incorrect_50less2 = incorrect_50less2 +1
      }
    }
  }
  return(c(correct_50plus2, incorrect_50plus2, correct_50less2, incorrect_50less2))
}
```

For our final results, we got the coefficients from the Logistic Regression (these coefficients include implementations with and without Bag of Little Bootstraps). The results have been formatted as a table in the following order: Simple Logistic Regression without Bootstrap, then BLBGLM with Mean, BLBGLM with Median, BLBGLM with Confidence Intervals.    
```{r, warning=FALSE, message=FALSE}
coeffs_df<-as.data.frame(cbind(coeffs_simple, mean_coeffs, med_coeffs, ci_coeffs))
coeffs_df <- coeffs_df %>% 
  rename(Coefficients_Simple=coeffs_simple)
formattable(coeffs_df)
```

The table input for accuracy is based on the following models: GLM on the full model, GLM without bootstrap (selected), then BLBGLM with mean, BLBGLM with median, BLBGLM with confidence intervals.      
```{r, warning=FALSE, message=FALSE}
library(formattable)
#use mean1 to calculate an accuracy vector on the test data
accuracy_mean<- predict_blb_glm(mean1, data1_test)
mean_rate<- (accuracy_mean[1]+accuracy_mean[3])/(nrow(data1_test))*100
#use med1 to calculate an accuracy vector on the test data
accuracy_median<- predict_blb_glm(med1, data1_test)
median_rate<- (accuracy_median[1]+accuracy_median[3])/(nrow(data1_test))*100
#use the confidence interval to calculate an accuracy vector on the test data
accuracy_ci1<- predict_blb_glm(ci1[1,],data1_test) #this calculates for the lower bound
accuracy_ci2<- predict_blb_glm(ci1[2,],data1_test) #this calculates for the upper bound
ci1_rate<- (accuracy_ci1[1]+accuracy_ci1[3])/(nrow(data1_test))*100
ci2_rate<- (accuracy_ci2[1]+accuracy_ci2[3])/(nrow(data1_test))*100
accuracy_tree<- calc_accuracy_rf(data1_test,predict(tree_income, data1_test))
tree_rate <- (accuracy_tree[1]+accuracy_tree[3])/(nrow(data1_test))*100
accuracy_val2<-calc_accuracy_rf(data1_test,mean_rf)
#then we will get an accuracy rate 
rf_rate<-(accuracy_val2[1]+accuracy_val2[3])/(nrow(data1_test))*100
accuracy_rates<-as.data.frame(t(c(glm_rate_full, mean_rate, median_rate, ci1_rate, ci2_rate, glm_rate_m1, tree_rate, rf_rate))) %>% 
  rename("GLM (full, no bootstrap)"=V1,
         "Model 1, no bootsrap"=V2,
          "Mean Rate"=V3, 
         "Median Rate"=V4, 
         "CI Rate (Lower)"=V5,
         "CI Rate (Upper)"=V6,
         "Tree Rate" = V7,
         "Random Forest Rate"= V8)
formattable(accuracy_rates)
```
